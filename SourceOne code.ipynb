{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import sklearn.linear_model as linear_model\n",
    "import seaborn as sns\n",
    "#import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "from IPython.display import HTML, display\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('./LoanStats3a.csv')\n",
    "df = pd.read_csv('./Final_Dataset.csv')\n",
    "df_origin=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspecting the Null values\n",
    "df.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num = df.isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "perc = df.isnull().sum()/df.isnull().count() *100\n",
    "perc1 = (round(perc,2).sort_values(ascending=False))\n",
    "\n",
    "# Creating a data frame:\n",
    "df_miss = pd.concat([total_num, perc1], axis =1 , keys =[\"Total Missing Values\", \"Percentage %\"]).sort_values(by =\"Percentage %\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_mis = df_miss[df_miss[\"Percentage %\"]>0]\n",
    "top_mis.reset_index(inplace=True)\n",
    "top_mis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['Loss on Dispostion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add=df_origin[['App1RiskScore','App2RiskScore','Customers_Applicant_Gender','Vehicle_Trim','ProductSeries','DealerRegion','Customers_Applicant_EmpStatus','Customers_Applicant_EmpProvince',\n",
    "'CashSalePrice','Customers_CoApplicant_AnnualTotal']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.join(add)\n",
    "df=df.join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CashSalePrice'].fillna(df['CashSalePrice'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists number of unique values by each column\n",
    "df.apply(lambda x: x.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the columns which has single(unique) values like - NA, 0, 'f', 'n' etc.\n",
    "unique = df.nunique()\n",
    "unique = unique[unique.values == 1]\n",
    "unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the columns which has single(unique) values like - NA, 0, 'f', 'n' etc.\n",
    "df.drop(labels = list(unique.index), axis =1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Customers_CoApplicant_AnnualTotal']=df.Customers_CoApplicant_AnnualTotal.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Customers_CoApplicant_AnnualTotal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Customers_Applicant_AnnualTotal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Customers_Applicant_AnnualTotal']=df['Customers_Applicant_AnnualTotal'] + df['Customers_CoApplicant_AnnualTotal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 둘이 공동 대출이므로 하나의 건으로 본다.\n",
    "df['Customers_Applicant_AnnualTotal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공동대출 그룹과 개인 대출 그룹의 비교를 위해 바이너리 변수 하나를 만든다.\n",
    "df['Customers_CoApplicant'] =np.where(df['Customers_CoApplicant_AnnualTotal']>=1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop('Customers_CoApplicant_AnnualTotal', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# object 타입변수들 unique 개수 봐서 필요없는것 삭제\n",
    "df.select_dtypes('object').apply(pd.Series.nunique, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Customers_Applicant_PostalCode','CreatedOn','ApplicationNumber'], inplace=True, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#연속성 변수 상관관계로 다중공선선 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8)) \n",
    "plt.figure(1)\n",
    "corr = df.corr()\n",
    "sns.heatmap(corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr.loc[:,:] = np.tril(corr, k=-1)   # below main lower triangle of an array\n",
    "corr = corr.stack()\n",
    "corr[(corr > 0.65) | (corr < -0.65)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Customers_Applicant_ApplicationID','DecisionID', 'Decisions_Vehicles_Losses_ApplicationID','Decisions_Booked_isLastDecision_Distinct_DealerID','PortalApplicationID','App1RiskScore','App2RiskScore',\n",
    "       'Vehicles_Booked_Losses_DealerID','ProductYear','Vehicle_Year', 'ProductMileage','AmountToFinance', 'CoApplicantFlag','MonthlyIncome','LenderBookValue','LastAmountToFinance','PaymentFrequency','LTV_Value','InitialNumberOfApplicants'], inplace=True, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8)) \n",
    "plt.figure(1)\n",
    "corr = df.corr()\n",
    "\n",
    "sns.heatmap(corr, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Customers_Applicant_Province','ProductMake', 'ProductModel','LastRiskTierName','RiskTierCode','LastRiskTierName','CustomerProvince','Vehicle_Trim','DealerRegion','Customers_Applicant_EmpProvince','RiskTierName'], inplace=True, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=df['Loss on Dispostion'].dropna()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from scipy.stats import norm, skew #for some statistics\n",
    "\n",
    "sns.distplot(loss , fit=norm);\n",
    "\n",
    "# Get the fitted parameters used by the function\n",
    "(mu, sigma) = norm.fit(loss)\n",
    "print( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n",
    "\n",
    "#Now plot the distribution\n",
    "plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n",
    "            loc='best')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('distribution')\n",
    "\n",
    "#Get also the QQ-plot\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(loss, plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[df['Loss on Dispostion']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # default net loss : 1, Besides that: 0 \n",
    "# df['Loss on Dispostion'] =np.where(df['Loss on Dispostion']>0, 1, 0)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default :1, normal:0\n",
    "df['Loss on Dispostion'] = np.where(pd.notnull(df['Loss on Dispostion']), 1, 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,18))\n",
    "\n",
    "ax1 = fig.add_subplot(221)\n",
    "ax2 = fig.add_subplot(222)\n",
    "ax3 = fig.add_subplot(212)\n",
    "\n",
    "cmap = plt.cm.coolwarm_r\n",
    "\n",
    "loans_by_region = df.groupby(['RiskTier', 'Loss on Dispostion']).size()\n",
    "loans_by_region.unstack().plot(kind='bar', stacked=True, colormap=cmap, ax=ax1, grid=False)\n",
    "ax1.set_title('Type of Loans by RiskTier', fontsize=14)\n",
    "\n",
    "\n",
    "loans_by_grade = df.groupby(['Customers_Applicant_ResidentType', 'Loss on Dispostion']).size()\n",
    "loans_by_grade.unstack().plot(kind='bar', stacked=True, colormap=cmap, ax=ax2, grid=False)\n",
    "ax2.set_title('Type of Loans by ResidentType', fontsize=14)\n",
    "\n",
    "by_interest = df.groupby(['Term', 'Loss on Dispostion']).InterestRate.mean()\n",
    "by_interest.unstack().plot(ax=ax3, colormap=cmap)\n",
    "ax3.set_title('Average Interest rate by Loan Condition', fontsize=14)\n",
    "ax3.set_ylabel('Interest Rate (%)', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.InterestRate.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average interest is 25% Anything above this will be considered of high risk let's see if this is true.\n",
    "df['interest_payments'] = np.nan\n",
    "lst = [df]\n",
    "\n",
    "for col in lst:\n",
    "    col.loc[col['InterestRate'] <= 25, 'interest_payments'] = 'Low'\n",
    "    col.loc[col['InterestRate'] > 25, 'interest_payments'] = 'High'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "palette = ['#009393', '#930000']\n",
    "plt.subplot(221)\n",
    "ax = sns.countplot(x='interest_payments', data=df, \n",
    "                  palette=palette, hue='Loss on Dispostion')\n",
    "\n",
    "ax.set_title('The impact of interest rate \\n on the condition of the loan', fontsize=14)\n",
    "ax.set_xlabel('Level of Interest Payments', fontsize=12)\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "plt.subplot(222)\n",
    "ax1 = sns.countplot(x='interest_payments', data=df, \n",
    "                   palette=palette, hue='Customers_Applicant_Gender')\n",
    "\n",
    "ax1.set_title('The impact of interest rate \\n on status of sex', fontsize=14)\n",
    "ax1.set_xlabel('Level of Interest Payments', fontsize=12)\n",
    "ax1.set_ylabel('Count')\n",
    "\n",
    "\n",
    "plt.subplot(212)\n",
    "low = df['TotalCalculatedDebt'].loc[df['interest_payments'] == 'Low'].values\n",
    "high = df['TotalCalculatedDebt'].loc[df['interest_payments'] == 'High'].values\n",
    "\n",
    "\n",
    "ax2= sns.distplot(low, color='#009393', label='Low Interest Payments', fit=norm, fit_kws={\"color\":\"#483d8b\"}) # Dark Blue Norm Color\n",
    "ax3 = sns.distplot(high, color='#930000', label='High Interest Payments', fit=norm, fit_kws={\"color\":\"#c71585\"}) #  Red Norm Color\n",
    "plt.axis([0, 36000, 0, 0.00016])\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['Loss on Dispostion']\n",
    "x=df.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantitative = [f for f in df.columns if df.dtypes[f] != 'object']\n",
    "qualitative = [f for f in df.columns if df.dtypes[f] == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing categories imoutation\n",
    "for c in qualitative:\n",
    "    df[c] = df[c].astype('category')\n",
    "    if df[c].isnull().any():\n",
    "        df[c] = df[c].cat.add_categories(['MISSING'])\n",
    "        df[c] = df[c].fillna('MISSING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encording\n",
    "\n",
    "from scipy.stats import trim_mean\n",
    "# m = stats.trim_mean(train[''], 0.1) # Trim 10% at both ends of the mean 극단치 제외하기위해 mean 대신 trim_mean 사용\n",
    "    \n",
    "def encode(frame, feature):\n",
    "    ordering = pd.DataFrame()\n",
    "    ordering['val'] = frame[feature].unique() #각 특성의 카테고리값을 val에 넣었다\n",
    "    ordering.index = ordering.val\n",
    "    ordering['spmean'] = frame[[feature, 'Loss on Dispostion']].groupby(feature)['Loss on Dispostion'].apply(trim_mean, 0.1) #각 특성의 카테고리값의 credit_score 평균을 spmean에 넣는다\n",
    "    ordering = ordering.sort_values('spmean') # credit_score 평균값이 작은 카테고리부터 sort된다.\n",
    "    ordering['ordering'] = range(1, ordering.shape[0]+1) # 1부터 카데고리수만큼 순서를 정한후\n",
    "    ordering = ordering['ordering'].to_dict() #딕셔너리 키밸류 셋으로 만든후\n",
    "    \n",
    "    for cat, o in ordering.items(): # 키,밸류 뽑아서\n",
    "        frame.loc[frame[feature] == cat, feature+'_E'] = o # 카테고리 이름과 변수 이름이 만나는 행렬의 밸류값 즉 credit_score평균값을 꺼낸다.\n",
    "    \n",
    "qual_encoded_C = []\n",
    "for q in qualitative:  \n",
    "    encode(df, q)\n",
    "    qual_encoded_C.append(q+'_E')\n",
    "print(qual_encoded_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코딩한 데이터로 대체해서 df 새로 만듬\n",
    "df_C=df[quantitative+qual_encoded_C]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_C.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anova(frame):\n",
    "    anv = pd.DataFrame()\n",
    "    anv['feature'] = qualitative #질적 변수들을 사용\n",
    "    pvals = []\n",
    "    for c in qualitative:\n",
    "        samples = []\n",
    "        for cls in frame[c].unique(): # 각 독립변수의 카테고리들간의 SalePrice 평균값의 차이가 유의미 한지 ANOVA로 분석\n",
    "            s = frame[frame[c] == cls]['Loss on Dispostion'].values\n",
    "            samples.append(s)\n",
    "        pval = stats.f_oneway(*samples)[1]\n",
    "        pvals.append(pval)\n",
    "    anv['pval'] = pvals \n",
    "    return anv.sort_values('pval') \n",
    "\n",
    "a = anova(df)\n",
    "a['disparity'] = np.log(1./a['pval'].values) # p-value를 역으로 해서 차이가 큰거부터 줄어들도록 표시.\n",
    "sns.barplot(data=a, x='feature', y='disparity')\n",
    "x=plt.xticks(rotation=90)\n",
    "\n",
    "#p-value 작은거 부터 왼쪽에 오도록 한다. 즉, 카테고리들간의 종속변수에 대한 평균값 차이가 큰거부터 왼쪽. \n",
    "#왼쪽변수일수록 종속변수에 대한 영향력이 크다. 카테고리들 간의 분포가 유의미 하게 차이가 나기 때문이다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spearman(frame, features):\n",
    "    spr = pd.DataFrame()\n",
    "    spr['feature'] = features\n",
    "    spr['spearman'] = [frame[f].corr(frame['Loss on Dispostion'], 'spearman') for f in features]\n",
    "    spr = spr.sort_values('spearman')\n",
    "    plt.figure(figsize=(6, 0.25*len(features)))\n",
    "    sns.barplot(data=spr, y='feature', x='spearman', orient='h')\n",
    "    \n",
    "features = quantitative + qual_encoded_C\n",
    "spearman(df_C, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#변수 그룹별 상관관계\n",
    "#Correlation matrix\n",
    "\n",
    "plt.figure(figsize=(10, 8)) \n",
    "plt.figure(1)\n",
    "corr = df[quantitative+['Loss on Dispostion']].corr()\n",
    "sns.heatmap(corr)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.figure(2)\n",
    "corr = df[qual_encoded_C+['Loss on Dispostion']].corr()\n",
    "sns.heatmap(corr)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.figure(3)\n",
    "corr = pd.DataFrame(np.zeros([len(quantitative)+1, len(qual_encoded_C)+1]), index=quantitative+['Loss on Dispostion'], columns=qual_encoded_C+['Loss on Dispostion'])\n",
    "for q1 in quantitative+['Loss on Dispostion']:\n",
    "    for q2 in qual_encoded_C+['Loss on Dispostion']:\n",
    "        corr.loc[q1, q2] = df[q1].corr(df[q2])\n",
    "sns.heatmap(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def boxplot(x, y, **kwargs):\n",
    "    sns.boxplot(x=x, y=y)\n",
    "    x=plt.xticks(rotation=90)\n",
    "f = pd.melt(df, id_vars=['Loss on Dispostion'], value_vars=qualitative)\n",
    "g = sns.FacetGrid(f, col=\"variable\",  col_wrap=2, sharex=False, sharey=False, size=5)\n",
    "g = g.map(boxplot, \"value\", \"Loss on Dispostion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairplot 에서 loan_condition_E값으로 melt 하기 위해서는 겹쳐지니 뺸다.\n",
    "quantitative.remove('Loss on Dispostion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def pairplot(x, y, **kwargs):\n",
    "    ax = plt.gca()\n",
    "    ts = pd.DataFrame({'time': x, 'val': y})\n",
    "    ts = ts.groupby('time').mean()\n",
    "    ts.plot(ax=ax)\n",
    "    plt.xticks(rotation=90)\n",
    "    \n",
    "f = pd.melt(df_C, id_vars=['Loss on Dispostion'], value_vars=quantitative+qual_encoded_C)\n",
    "g = sns.FacetGrid(f, col=\"variable\",  col_wrap=2, sharex=False, sharey=False, size=5)\n",
    "g = g.map(pairplot, \"value\", \"Loss on Dispostion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_C.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and labels \n",
    "\n",
    "Label = df_C['Loss on Dispostion']\n",
    "features = df_C.drop('Loss on Dispostion', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VIF 검사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(\n",
    "    df_C.values, i) for i in range(df_C.shape[1])]\n",
    "vif[\"features\"] = df_C.columns\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "model1 = sm.OLS(Label, features)\n",
    "result1 = model1.fit()\n",
    "print(result1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr=df_C.corr()\n",
    "corr.loc[:,:] = np.tril(corr, k=-1)   # below main lower triangle of an array\n",
    "corr = corr.stack()\n",
    "corr[(corr > 0.65) | (corr < -0.65)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_C= df_C.drop('interest_payments_E',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and labels \n",
    "\n",
    "Label = df_C['Loss on Dispostion']\n",
    "features = df_C.drop('Loss on Dispostion', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model1 = sm.OLS(Label, features)\n",
    "result1 = model1.fit()\n",
    "print(result1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr=df_C.corr()\n",
    "corr.loc[:,:] = np.tril(corr, k=-1)   # below main lower triangle of an array\n",
    "corr = corr.stack()\n",
    "corr[(corr > 0.6) | (corr < -0.6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(\n",
    "    df_C.values, i) for i in range(df_C.shape[1])]\n",
    "vif[\"features\"] = df_C.columns\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_C= df_C.drop('InterestRate',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and labels \n",
    "\n",
    "Label = df_C['Loss on Dispostion']\n",
    "features = df_C.drop('Loss on Dispostion', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Testing Sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터를 훈련+검증 세트 그리고 테스트 세트로 분할\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    features, Label, random_state=0)\n",
    "# 훈련+검증 세트를 훈련 세트와 검증 세트로 분할\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_trainval, y_trainval, random_state=1)\n",
    "print(\"train 세트의 크기: {}   validate 세트의 크기: {}   test 세트의 크기:\"\n",
    "      \" {}\\n\".format(X_train.shape[0], X_valid.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 데이터 전처리 - 데이터 표준화 작업 (scaling)\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler  # 0~1 사이의 숫자로 바꾼다. 양수가 필요할때 변환\n",
    "\n",
    "sc = RobustScaler()\n",
    "transformer = sc.fit(X_train)\n",
    "transformer\n",
    "\n",
    "sc2= StandardScaler()\n",
    "transformer2 = sc2.fit(X_train)\n",
    "\n",
    "sc3= MinMaxScaler()\n",
    "transformer3 = sc3.fit(X_train)\n",
    "\n",
    "# 4분위수를 이용한 표준화 스케일 방법인 RobustScaler를 이용.이상치 영향 약화. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#위에서 training set으로 fit 시킨 평균,분산 값을 이용하여 각 세트의 독립변수(X)들을 변환시킨다. \n",
    "X_train_std=transformer.transform(X_train)\n",
    "X_valid_std=transformer.transform(X_valid)\n",
    "X_test_std=transformer.transform(X_test)\n",
    "\n",
    "\n",
    "X_train_std2=transformer2.transform(X_train)\n",
    "X_valid_std2=transformer2.transform(X_valid)\n",
    "X_test_std2=transformer2.transform(X_test)\n",
    "\n",
    "X_train_std3=transformer3.transform(X_train)\n",
    "X_valid_std3=transformer3.transform(X_valid)\n",
    "X_test_std3=transformer3.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(\n",
    "    X_train.values, i) for i in range(X_train.shape[1])]\n",
    "vif[\"features\"] = X_train.columns\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "import copy\n",
    "import chart_studio.plotly as py\n",
    "\n",
    "from plotly.offline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## target Proportion ##\n",
    "cnt = df_C['Loss on Dispostion'].value_counts()\n",
    "tr_prop = go.Bar(\n",
    "    x=cnt.index,\n",
    "    y=cnt.values,\n",
    "    marker=dict(\n",
    "        color=cnt.values,\n",
    "        colorscale = 'Picnic',\n",
    "        reversescale = True\n",
    "    ),\n",
    ")\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Default Proportion',\n",
    "    font=dict(size=18)\n",
    ")\n",
    "\n",
    "data = [tr_prop]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig, filename=\"TargetProp\")\n",
    "\n",
    "## target distribution ##\n",
    "labels = (np.array(cnt.index))\n",
    "sizes = (np.array((cnt / cnt.sum())*100))\n",
    "\n",
    "tr_pie = go.Pie(labels=labels, values=sizes)\n",
    "layout = go.Layout(\n",
    "    title='Default Pie chart',\n",
    "    font=dict(size=18),\n",
    "    width=600,\n",
    "    height=600,\n",
    ")\n",
    "data = [tr_pie]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig, filename=\"pie_ty\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values_table(df):\n",
    "        # Total missing values\n",
    "        mis_val = df.isnull().sum()\n",
    "        \n",
    "        # Percentage of missing values\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        \n",
    "        # Make a table with the results\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        \n",
    "        # Rename the columns\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        \n",
    "        # Sort the table by percentage of missing descending\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "        \n",
    "        # Print some summary information\n",
    "        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
    "            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "              \" columns that have missing values.\")\n",
    "        \n",
    "        # Return the dataframe with missing information\n",
    "        return mis_val_table_ren_columns\n",
    "\n",
    "missing_values_table(df_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "labels = []\n",
    "values = []\n",
    "for col in df_C.columns:\n",
    "    if col not in [\"Loss on Dispostion\"]:\n",
    "        labels.append(col)\n",
    "        values.append(spearmanr(df_C[col].values, df_C[\"Loss on Dispostion\"].values)[0])\n",
    "corr_df = pd.DataFrame({'col_labels':labels, 'corr_values':values})\n",
    "corr_df = corr_df.sort_values(by='corr_values')\n",
    " \n",
    "ind = np.arange(corr_df.shape[0])\n",
    "width = 0.9\n",
    "fig, ax = plt.subplots(figsize=(12,30))\n",
    "rects = ax.barh(ind, np.array(corr_df.corr_values.values), color='g')\n",
    "ax.set_yticks(ind)\n",
    "ax.set_yticklabels(corr_df.col_labels.values, rotation='horizontal')\n",
    "ax.set_xlabel(\"Correlation coefficient\")\n",
    "ax.set_title(\"Correlation coefficient of the variables\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_use = corr_df.ix[(corr_df['corr_values'] < -0.05) | (corr_df['corr_values']>0.05)].col_labels.tolist()\n",
    "\n",
    "temp_df = df_C[cols_to_use]\n",
    "corrmat = temp_df.corr(method='spearman')\n",
    "f, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "# Draw the heatmap using seaborn\n",
    "sns.heatmap(corrmat, vmax=1., square=True, cmap=\"YlGnBu\", annot=True)\n",
    "plt.title(\"Important variables correlation map\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc_model = RandomForestClassifier(random_state=0).fit(X_train, y_train)\n",
    "\n",
    "#Feature importance by eli5\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "perm = PermutationImportance(rfc_model, random_state=1).fit(X_valid, y_valid)\n",
    "eli5.show_weights(perm, feature_names = X_valid.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PermutationImportance\n",
    "Interpreting Permutation Importances The values towards the top are the most important features, and those towards the bottom matter least.\n",
    "\n",
    "The first number in each row shows how much model performance decreased with a random shuffling (in this case, using \"accuracy\" as the performance metric).\n",
    "\n",
    "Like most things in data science, there is some randomness to the exact performance change from a shuffling a column. We measure the amount of randomness in our permutation importance calculation by repeating the process with multiple shuffles. The number after the ± measures how performance varied from one-reshuffling to the next.\n",
    "\n",
    "You'll occasionally see negative values for permutation importances. In those cases, the predictions on the shuffled (or noisy) data happened to be more accurate than the real data. This happens when the feature didn't matter (should have had an importance close to 0), but random chance caused the predictions on shuffled data to be more accurate. This is more common with small datasets, like the one in this example, because there is more room for luck/chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# perm.feature_importances_ attribute is now available, it can be used\n",
    "# for feature selection - let's e.g. select features which increase\n",
    "# accuracy by at least 0.05:\n",
    "sel = SelectFromModel(perm, threshold=0.05, prefit=True)\n",
    "X_trans = sel.transform(X_train_std)\n",
    "X_trans\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(random_state=42)\n",
    "forest.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"훈련 세트 정확도: {:.3f}\".format(forest.score(X_train_std, y_train)))\n",
    "print(\"테스트 세트 정확도: {:.3f}\".format(forest.score(X_valid_std, y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"훈련 세트 정확도: {:.3f}\".format(forest.score(X_train_std, y_train)))\n",
    "print(\"테스트 세트 정확도: {:.3f}\".format(forest.score(X_test_std, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "forest.fit(X_train_std, y_train)\n",
    "y_pred = forest.predict(X_test_std)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=['current', 'default']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "y_hat = forest.predict(X_test_std)\n",
    "score = roc_auc_score(y_test, y_hat)\n",
    "print(\"Overall AUC: {:.3f}\" .format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output feature importance coefficients, map them to their feature name, and sort values\n",
    "coef = pd.Series(forest.feature_importances_, index = X_train.columns).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "coef.head(25).plot(kind='bar')\n",
    "plt.title('Feature Significance')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbrt = GradientBoostingClassifier(random_state=42)\n",
    "gbrt.fit(X_train_std, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "rfc_model = GradientBoostingClassifier(random_state=42).fit(X_train_std, y_train)\n",
    "\n",
    "#Feature importance by eli5\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "perm = PermutationImportance(rfc_model, random_state=1).fit(X_valid_std, y_valid)\n",
    "eli5.show_weights(perm, feature_names = X_valid.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"훈련 세트 정확도: {:.3f}\".format(gbrt.score(X_train_std, y_train)))\n",
    "print(\"테스트 세트 정확도: {:.3f}\".format(gbrt.score(X_valid_std, y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 테스트 (위에서 가장 성능좋은것 실행후 하자 이름이 모두 gbrt로 같기 때문.)\n",
    "print(\"훈련 세트 정확도: {:.3f}\".format(gbrt.score(X_train_std, y_train)))\n",
    "print(\"테스트 세트 정확도: {:.3f}\".format(gbrt.score(X_test_std, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numerical feature importances\n",
    "\n",
    "feature_list = list(X_train.columns)\n",
    "importances = list(gbrt.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances]\n",
    "\n",
    "# list of x locations for plotting\n",
    "x_values = list(range(len(importances)))\n",
    "# Make a bar chart\n",
    "plt.bar(x_values, importances, orientation = 'vertical', color = 'r', edgecolor = 'k', linewidth = 1.2)\n",
    "# Tick labels for x axis\n",
    "plt.xticks(x_values, feature_list, rotation='vertical')\n",
    "# Axis labels and title\n",
    "plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of features sorted from most to least important\n",
    "sorted_importances = [importance[1] for importance in feature_importances]\n",
    "sorted_features = [importance[0] for importance in feature_importances]\n",
    "# Cumulative importances\n",
    "cumulative_importances = np.cumsum(sorted_importances)\n",
    "# Make a line graph\n",
    "plt.plot(x_values, cumulative_importances, 'g-')\n",
    "# Draw line at 80% of importance retained\n",
    "plt.hlines(y = 0.80, xmin=0, xmax=len(sorted_importances), color = 'r', linestyles = 'dashed')\n",
    "# Format x ticks and labels\n",
    "plt.xticks(x_values, sorted_features, rotation = 'vertical')\n",
    "# Axis labels and title\n",
    "plt.xlabel('Variable'); plt.ylabel('Cumulative Importance'); plt.title('Cumulative Importances');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# fit model no training data\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train_std, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "rfc_model = XGBClassifier(random_state=42).fit(X_train_std, y_train)\n",
    "\n",
    "#Feature importance by eli5\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "perm = PermutationImportance(rfc_model, random_state=1).fit(X_valid_std, y_valid)\n",
    "eli5.show_weights(perm, feature_names = X_valid.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"훈련 세트 정확도: {:.3f}\".format(xgb.score(X_train_std, y_train)))\n",
    "print(\"테스트 세트 정확도: {:.3f}\".format(xgb.score(X_valid_std, y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"훈련 세트 정확도: {:.3f}\".format(xgb.score(X_train_std, y_train)))\n",
    "print(\"테스트 세트 정확도: {:.3f}\".format(xgb.score(X_test_std, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# make predictions for test data\n",
    "y_pred = xgb.predict(X_test_std)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numerical feature importances\n",
    "\n",
    "feature_list = list(X_train.columns)\n",
    "importances = list(xgb.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances]\n",
    "\n",
    "# list of x locations for plotting\n",
    "x_values = list(range(len(importances)))\n",
    "# Make a bar chart\n",
    "plt.bar(x_values, importances, orientation = 'vertical', color = 'r', edgecolor = 'k', linewidth = 1.2)\n",
    "# Tick labels for x axis\n",
    "plt.xticks(x_values, feature_list, rotation='vertical')\n",
    "# Axis labels and title\n",
    "plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of features sorted from most to least important\n",
    "sorted_importances = [importance[1] for importance in feature_importances]\n",
    "sorted_features = [importance[0] for importance in feature_importances]\n",
    "# Cumulative importances\n",
    "cumulative_importances = np.cumsum(sorted_importances)\n",
    "# Make a line graph\n",
    "plt.plot(x_values, cumulative_importances, 'g-')\n",
    "# Draw line at 80% of importance retained\n",
    "plt.hlines(y = 0.80, xmin=0, xmax=len(sorted_importances), color = 'r', linestyles = 'dashed')\n",
    "# Format x ticks and labels\n",
    "plt.xticks(x_values, sorted_features, rotation = 'vertical')\n",
    "# Axis labels and title\n",
    "plt.xlabel('Variable'); plt.ylabel('Cumulative Importance'); plt.title('Cumulative Importances');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "gbrt.fit(X_train_std, y_train)\n",
    "y_pred = gbrt.predict(X_test_std)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cm[0,0]+cm[1,1])/np.sum(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=['current', 'default']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "y_hat = gbrt.predict(X_test_std)\n",
    "score = roc_auc_score(y_test, y_hat)\n",
    "print(\"Overall AUC: {:.3f}\" .format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: ', mse)\n",
    "print('R2 score: ', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "y_hat = gbrt.predict(X_test_std)\n",
    "score = roc_auc_score(y_test, y_hat)\n",
    "print(\"Overall AUC: {:.3f}\" .format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "y_pred_proba = gbrt.predict_proba(X_valid_std)[::,1]\n",
    "fpr, tpr, _ = roc_curve(y_valid, y_pred_proba, pos_label=1) \n",
    "# fpr, tpr, _ = metrics.roc_curve(y_valid,  y_pred_proba)\n",
    "auc = metrics.roc_auc_score(y_valid, y_pred_proba)\n",
    "plt.plot(fpr,tpr,label=\"ROC Curve, auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "    \n",
    "y_pred_prob = gbrt.predict_proba(X_valid_std)[:,1]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_valid, y_pred_prob, pos_label=1)\n",
    "auc = metrics.roc_auc_score(y_valid, y_pred_prob)\n",
    "\n",
    "# create plot\n",
    "plt.plot(fpr, tpr, label='ROC curve,  auc='+str(auc))\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random guess')\n",
    "_ = plt.xlabel('False Positive Rate')\n",
    "_ = plt.ylabel('True Positive Rate')\n",
    "_ = plt.title('ROC Curve')\n",
    "_ = plt.xlim([-0.02, 1])\n",
    "_ = plt.ylim([0, 1.02])\n",
    "_ = plt.legend(loc=\"lower right\")\n",
    "\n",
    "\n",
    "# save figure\n",
    "#plt.savefig('roc_curve.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "    \n",
    "y_pred_prob = gbrt.predict_proba(X_valid_std)[:,0]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_valid, y_pred_prob, pos_label=0)\n",
    "auc = metrics.roc_auc_score(y_valid, y_pred_prob)\n",
    "\n",
    "# create plot\n",
    "plt.plot(fpr, tpr, label='ROC curve,  auc='+str(auc))\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random guess')\n",
    "_ = plt.xlabel('False Positive Rate')\n",
    "_ = plt.ylabel('True Positive Rate')\n",
    "_ = plt.title('ROC Curve')\n",
    "_ = plt.xlim([-0.02, 1])\n",
    "_ = plt.ylim([0, 1.02])\n",
    "_ = plt.legend(loc=\"lower right\")\n",
    "\n",
    "\n",
    "# save figure\n",
    "#plt.savefig('roc_curve.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve \n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "precision_score= average_precision_score(y_valid, y_pred_prob,pos_label=0)\n",
    "precision, recall, thresholds = precision_recall_curve(y_valid, y_pred_prob, pos_label=0)\n",
    "\n",
    "# create plot\n",
    "plt.plot(precision, recall, label='Precision-recall curve,  AP='+str(precision_score))\n",
    "_ = plt.xlabel('Recall')\n",
    "_ = plt.ylabel('Precision')\n",
    "_ = plt.title('Precision-recall curve')\n",
    "_ = plt.xlim([0.735, 1])\n",
    "_ = plt.ylim([0, 1.02])\n",
    "_ = plt.legend(loc=\"lower left\")\n",
    "\n",
    "# save figure\n",
    "# plt.savefig('precision_recall.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve \n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "precision_score= average_precision_score(y_valid, y_pred_prob,pos_label=1)\n",
    "precision, recall, thresholds = precision_recall_curve(y_valid, y_pred_prob, pos_label=1)\n",
    "\n",
    "# create plot\n",
    "plt.plot(precision, recall, label='Precision-recall curve,  AP='+str(precision_score))\n",
    "_ = plt.xlabel('Recall')\n",
    "_ = plt.ylabel('Precision')\n",
    "_ = plt.title('Precision-recall curve')\n",
    "_ = plt.xlim([0.735, 1])\n",
    "_ = plt.ylim([0, 1.02])\n",
    "_ = plt.legend(loc=\"lower left\")\n",
    "\n",
    "# save figure\n",
    "# plt.savefig('precision_recall.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "average_precision = average_precision_score(y_valid, y_pred_prob,pos_label=0)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.utils.fixes import signature\n",
    "from inspect import signature\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_valid, y_pred_prob, pos_label=0)\n",
    "\n",
    "# In matplotlib < 1.5, plt.fill_between does not have a 'step' argument\n",
    "step_kwargs = ({'step': 'post'}\n",
    "               if 'step' in signature(plt.fill_between).parameters\n",
    "               else {})\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
    "          average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "average_precision = average_precision_score(y_valid, y_pred_prob,pos_label=1)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.utils.fixes import signature\n",
    "from inspect import signature\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_valid, y_pred_prob, pos_label=1)\n",
    "\n",
    "# In matplotlib < 1.5, plt.fill_between does not have a 'step' argument\n",
    "step_kwargs = ({'step': 'post'}\n",
    "               if 'step' in signature(plt.fill_between).parameters\n",
    "               else {})\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
    "          average_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "log_clf = LogisticRegression(random_state=42)\n",
    "rnd_clf = RandomForestClassifier(random_state=42)\n",
    "svm_clf = SVC(random_state=42)\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=15)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf),('knn', knn_clf) ],\n",
    "    voting='hard')\n",
    "voting_clf.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, knn_clf, voting_clf):\n",
    "    clf.fit(X_train_std, y_train)\n",
    "    y_pred = clf.predict(X_valid_std)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf = LogisticRegression(random_state=42)\n",
    "rnd_clf = RandomForestClassifier(random_state=42)\n",
    "svm_clf = SVC(random_state=42)\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=15)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf),('knn', knn_clf) ],\n",
    "    voting='soft')\n",
    "voting_clf.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, knn_clf, voting_clf):\n",
    "    clf.fit(X_train_std, y_train)\n",
    "    y_pred = clf.predict(X_valid_std)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### voting='soft' 인 경우 각 분류기의 예측값(레이블)의 확률을 가지고 평균을 구한 뒤, 평균이 가장 높은 클래스로 최종 앙상블 예측이 이루어진다. 이러한 방법을 간접 투표(soft voting)이라 한다. 이 경우에는 레이블의 확률값을 구할수 없기에 에러가 난다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 데이터 전처리 - 데이터 표준화 작업 (scaling)\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "sc = RobustScaler()\n",
    "transformer = sc.fit(features)\n",
    "transformer\n",
    "\n",
    "#위에서 training set으로 fit 시킨 평균,분산 값을 이용하여 각 세트의 독립변수(X)들을 변환시킨다. \n",
    "features_std=transformer.transform(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "skf=StratifiedKFold(n_splits=10, shuffle=True,random_state=0)\n",
    "score=cross_val_score(gbrt,features_std, Label, cv=skf)\n",
    "print(score)\n",
    "print(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-validation 을 사용하여 평가한 모델을 이용하여 예측\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "y_predict = cross_val_predict(gbrt,features_std, Label, cv=skf)\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "cv_results = cross_validate(gbrt,features_std, Label, cv=skf)\n",
    "print(sorted(cv_results.keys()))\n",
    "#print(cv_results['train_score'])\n",
    "print(cv_results['test_score'])\n",
    "print(cv_results['test_score'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(Label, y_predict, target_names=['current', 'default']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(Label, y_predict)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cm[0,0]+cm[1,1])/np.sum(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "y_hat = gbrt.predict(X_test_std)\n",
    "score = roc_auc_score(y_test, y_hat)\n",
    "print(\"Overall AUC: {:.3f}\" .format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_v['crossval_result']=y_predict.tolist()\n",
    "# df_v['compare'] = np.where(df['Loss on Dispostion'] == df_v['crossval_result'], '0', '1')\n",
    "# df_v['compare'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4878/len(df_cv['compare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf=StratifiedKFold(n_splits=10, shuffle=True,random_state=0)\n",
    "cv_results = cross_validate(gbrt,features_std, Label, cv=skf, return_estimator =True)\n",
    "\n",
    "\n",
    "for idx,estimator in enumerate(cv_results['estimator']):\n",
    "    print(\"Features sorted by their score for estimator {}:\".format(idx))\n",
    "    feature_importances = pd.DataFrame(estimator.feature_importances_,\n",
    "                                       index = features.columns,\n",
    "                                        columns=['importance']).sort_values('importance', ascending=False)\n",
    "    print(feature_importances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결론: cross-validation을 사용하여 predict 해보니기존의 train,test set 나눈후 모델 적용시킨 결과보다  default 예측이 더 높았다. 그것은 전체 데이터수가 적은데다가 또한 임의로 한번 데이터셋을 나누었을때 default 데이터가 균등히 섞이지 않았을 가능성이 높아서 default 예측 성능이 떨어진 것이다.  이런경우 cross-validation, 특히 StratifiedKFold 적용의 효과를 볼수있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "plt.subplot(121)\n",
    "g = sns.distplot(df[\"Loss on Dispostion\"])\n",
    "g.set_xlabel(\"\", fontsize=12)\n",
    "g.set_ylabel(\"Frequency Dist\", fontsize=12)\n",
    "g.set_title(\"Frequency Distribuition\", fontsize=20)\n",
    "\n",
    "plt.subplot(122)\n",
    "g1 = sns.violinplot(y=\"Loss on Dispostion\", data=df, \n",
    "               inner=\"quartile\", palette=\"hls\")\n",
    "g1.set_xlabel(\"\", fontsize=12)\n",
    "g1.set_ylabel(\"Amount Dist\", fontsize=12)\n",
    "g1.set_title(\"Amount Distribuition\", fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Loss on Dispostion'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p=df_C[['DealerCode_E','ProductSeries_E','Vehicle_Model_E','CurrentKms','Payment','Customers_Applicant_Age','LTV','Customers_Applicant_AnnualTotal','TotalCalculatedDebt','Loss on Dispostion']]\n",
    "df_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_p.sort_values(by='loan_condition_E')\n",
    "df_p.groupby(df_p['Loss on Dispostion']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_C.DealerCode_E.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "df_D=pd.concat([df_C.DealerCode_E,df.DealerCode], axis=1)\n",
    "df_D.sort_values(by='DealerCode_E')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count=df_D.groupby(df_D.DealerCode_E).count().sort_values('DealerCode', ascending=False)\n",
    "df_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s=pd.concat([df_C.ProductSeries_E,df.ProductSeries], axis=1)\n",
    "df_s.sort_values(by='ProductSeries_E')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v=pd.concat([df_C.Vehicle_Model_E,df.Vehicle_Model], axis=1)\n",
    "df_v.sort_values(by='Vehicle_Model_E')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE Over-Sampling\n",
    "As we have more records for target '0', I am going to over sample the target '1' to the same level as target '0' which is basically oversampling the least class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using SMOTE for class imbalance in target\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_resamp, y_resamp = sm.fit_sample(X_train_std, y_train)\n",
    "print('Resampled dataset shape %s' % Counter(y_resamp))\n",
    "X_resamp = pd.DataFrame(X_resamp)\n",
    "y_resamp = pd.DataFrame({\"target\": y_resamp})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_resamp, forest.predict(X_resamp),target_names=['current', 'default']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_resamp, gbrt.predict(X_resamp),target_names=['current', 'default']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves': 9,\n",
    "         'min_data_in_leaf': 42,\n",
    "         'objective': 'binary',\n",
    "         'max_depth': 16,\n",
    "         'learning_rate': 0.0123,\n",
    "         'boosting': 'gbdt',\n",
    "         'bagging_freq': 5,\n",
    "         'bagging_fraction': 0.8,\n",
    "         'feature_fraction': 0.8201,\n",
    "         'bagging_seed': 11,\n",
    "         'reg_alpha': 1.728910519108444,\n",
    "         'reg_lambda': 4.9847051755586085,\n",
    "         'random_state': 42,\n",
    "         'metric': 'auc',\n",
    "         'verbosity': -1,\n",
    "         'subsample': 0.81,\n",
    "         'min_gain_to_split': 0.01077313523861969,\n",
    "         'min_child_weight': 19.428902804238373,\n",
    "         'num_threads': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parameters to search\n",
    "gridParams = {\n",
    "    'learning_rate': [0.005],\n",
    "    'n_estimators': [40],\n",
    "    'num_leaves': [6,8,12,16],\n",
    "    'boosting_type' : ['gbdt'],\n",
    "    'objective' : ['binary'],\n",
    "    'random_state' : [501], # Updated from 'seed'\n",
    "    'colsample_bytree' : [0.65, 0.66],\n",
    "    'subsample' : [0.7,0.75],\n",
    "    'reg_alpha' : [1,1.2],\n",
    "    'reg_lambda' : [1,1.2,1.4],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "fold_n=3\n",
    "folds = StratifiedKFold(n_splits=fold_n, shuffle=True, random_state=30)\n",
    "y_pred_lgb = np.zeros(len(X_test_std))\n",
    "for fold_n, (train_index, valid_index) in enumerate(folds.split(X_resamp,y_resamp)):\n",
    "    print('Fold', fold_n, 'started at', time.ctime())\n",
    "    X_train, X_valid = X_resamp.iloc[train_index], X_resamp.iloc[valid_index]\n",
    "    y_train, y_valid = y_resamp.iloc[train_index], y_resamp.iloc[valid_index]\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "        \n",
    "    lgb_model = lgb.train(params,train_data,num_boost_round=20000,\n",
    "                    valid_sets = [train_data, valid_data],verbose_eval=300,early_stopping_rounds = 200)\n",
    "            \n",
    "    y_pred_lgb += lgb_model.predict(X_test_std, num_iteration=lgb_model.best_iteration)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "mse = mean_squared_error(y_test, y_pred_lgb)\n",
    "r2 = r2_score(y_test, y_pred_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: ', mse)\n",
    "print('R2 score: ', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "y_hat = lgb_model.predict(X_test_std)\n",
    "score = roc_auc_score(y_test, y_hat)\n",
    "print(\"Overall AUC: {:.3f}\" .format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = lgb.LGBMClassifier(class_weight='balanced',drop_rate=0.9, min_data_in_leaf=100, max_bin=255,\n",
    "                                 n_estimators=500,min_sum_hessian_in_leaf=1,importance_type='gain',learning_rate=0.1,bagging_fraction = 0.85,\n",
    "                                 colsample_bytree = 1.0,feature_fraction = 0.1,lambda_l1 = 5.0,lambda_l2 = 3.0,max_depth =  9,\n",
    "                                 min_child_samples = 55,min_child_weight = 5.0,min_split_gain = 0.1,num_leaves = 45,subsample = 0.75)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "# partially based on https://www.kaggle.com/c0conuts/xgb-k-folds-fastai-pca\n",
    "predicts = []\n",
    "for train_index, test_index in kf.split(X_resamp,y_resamp):\n",
    "    print(\"###\")\n",
    "    X_train, X_valid = X_resamp.iloc[train_index], X_resamp.iloc[valid_index]\n",
    "    y_train, y_valid = y_resamp.iloc[train_index], y_resamp.iloc[valid_index]\n",
    "    \n",
    "    clf.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], \n",
    "            early_stopping_rounds = 20)\n",
    "    predicts.append(clf.predict(X_test_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# sorted(zip(clf.feature_importances_, X.columns), reverse=True)\n",
    "feature_imp = pd.DataFrame(sorted(zip(clf.feature_importances_,features.columns)), columns=['Value','Feature'])\n",
    "\n",
    "plt.figure(figsize=(30, 30))\n",
    "sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\n",
    "plt.title('LightGBM Features (avg over folds)',fontsize=25)\n",
    "plt.tight_layout()\n",
    "\n",
    "#plt.rcParams.update({'font.size': 10})\n",
    "plt.show()\n",
    "plt.savefig('lgbm_importances-01.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = pd.concat([y_test.reset_index(drop=True), pd.DataFrame(y_pred_lgb)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result.columns = ['label','predict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x = 'label', y = 'predict', data = final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result.groupby(['label']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### parameter engineering 모델 성능 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "print(clf.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomizedSearchCV 를 위한 파라미터 조건 설정\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 50, stop = 550, num = 20)]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(5, 30, num = 5)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of child samples \n",
    "min_child_samples = [50, 55, 60]\n",
    "# drop rate\n",
    "drop_rate = [0.7, 0.8, 0.9]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               \n",
    "               'max_depth': max_depth,\n",
    "               'min_child_samples': min_child_samples,\n",
    "               \n",
    "               'drop_rate': drop_rate}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across (n_iter*cv) different combinations, and use all available cores\n",
    "clf_random = RandomizedSearchCV(estimator=clf, param_distributions=random_grid,\n",
    "                              n_iter = 10,  \n",
    "                              cv = 3, verbose=2, random_state=42, n_jobs=-1,\n",
    "                              return_train_score=True)\n",
    "\n",
    "# Fit the random search model\n",
    "clf_random.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], \n",
    "            early_stopping_rounds = 20);\n",
    "\n",
    "# n_iter, cv가 주요 하이퍼파라미터이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random = clf_random.best_estimator_\n",
    "\n",
    "y_pred=best_random.predict(X_test_std)\n",
    "print('Accuracy =', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the parameter grid based on the results of random search \n",
    "\n",
    "param_grid = {\n",
    "    'bootstrap': [True, False],\n",
    "    'max_depth': [30, 50],\n",
    "    'drop_rate': [0.8, 0.9],\n",
    "    'min_child_samples': [55,65],\n",
    "    'n_estimators': [130,155]\n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "# clf\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = clf, param_grid = param_grid, \n",
    "                          cv = 2, n_jobs = -1, verbose = 2, return_train_score=True)\n",
    "\n",
    "# Fit the random search model\n",
    "grid_search.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], \n",
    "            early_stopping_rounds = 20);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid = grid_search.best_estimator_\n",
    "\n",
    "y_pred=best_grid.predict(X_test_std)\n",
    "print('Accuracy =', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=df_p.iloc[:,0:9]\n",
    "inputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 데이터 전처리 - 데이터 표준화 작업 (scaling)\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "sc = RobustScaler()\n",
    "transformer = sc.fit(inputs)\n",
    "transformer\n",
    "\n",
    "inputs_std=X_train_std=transformer.transform(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Kmeans=KMeans(n_clusters=2)\n",
    "Kmeans.fit(inputs_std)\n",
    "Kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap=np.array(['red','blue','green','orange'])\n",
    "plt.scatter(inputs.CurrentKms, inputs.Payment, c=colormap[Kmeans.labels_],s=20)\n",
    "plt.title('kmeans cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Kmeans)\n",
    "print(Kmeans.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SSE(오차제곱합) 최소되도록 최적 k값 찾기 \n",
    "def elbow(x):\n",
    "    sse=[]\n",
    "    for i in range(1,11):\n",
    "        y=KMeans(n_clusters=i, init='k-means++', random_state=0)\n",
    "        y.fit(x)\n",
    "        sse.append(y.inertia_)\n",
    "\n",
    "    plt.plot(range(1,11),sse,marker='o')\n",
    "    plt.xlabel('cluster number')\n",
    "    plt.ylabel('SSE')\n",
    "    plt.show()\n",
    "\n",
    "elbow(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#정확한 답(클러스터의 갯수 및 소속)을 검사위해 clustring의 품질을 정량적으로 계산\n",
    "#Silhouette Coefficient\n",
    "#실루엣 계수가 1에 가까울수록 클러스터 n 최적화\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "X=inputs\n",
    "range_n_clusters = [2, 3, 4, 5, 6, 7]\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    # Create a subplot with 1 row and 2 columns\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(18, 7)\n",
    "\n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "    # lie within [-0.1, 1]\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 100])\n",
    "\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    \n",
    "    for i in range(n_clusters):\n",
    "        \n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = \\\n",
    "            sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        #color = cm.spectral(float(i) / n_clusters)\n",
    "        cmap = cm.get_cmap(\"Spectral\")\n",
    "        colors = cmap(float(i) / n_clusters)\n",
    "        \n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=colors, edgecolor=colors, alpha=0.7)\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i+1))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    # 2nd Plot showing the actual clusters formed\n",
    "    #colors = cm.spectral(cluster_labels.astype(float) / n_clusters)\n",
    "    \n",
    "    #color = cm.spectral(float(i) / n_clusters)\n",
    "    cmap = cm.get_cmap(\"Spectral\")\n",
    "    colors = cmap(float(i) / n_clusters)\n",
    "        \n",
    "    ax2.scatter(X.iloc[:, 3], X.iloc[:, 4], marker='.', s=30, lw=0, alpha=0.7,\n",
    "                c=colors)\n",
    "\n",
    "    # Labeling the clusters\n",
    "    centers = clusterer.cluster_centers_\n",
    "    # Draw white circles at cluster centers\n",
    "    ax2.scatter(centers[:, 3], centers[:, 4],\n",
    "                marker='o', c=\"yellow\", alpha=1, s=200)\n",
    "\n",
    "    for i, c in enumerate(centers):\n",
    "        r=i+1\n",
    "        ax2.scatter(c[3], c[4], marker='$%d$' % r, alpha=1, s=50)\n",
    "\n",
    "    ax2.set_title(\"The visualization of the clustered data.\")\n",
    "    ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
    "    ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
    "\n",
    "    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
    "                  \"with n_clusters = %d\" % n_clusters),\n",
    "                 fontsize=14, fontweight='bold')\n",
    "\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=inputs_std #data type (df->array)\n",
    "y=Kmeans.fit_predict(inputs_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y(집단)의 inputs 변수 두개의 분포를 보자.\n",
    "\n",
    "plt.scatter(x[y==0,3],x[y==0,4],c='lightgreen', marker='s',label='clu1')\n",
    "plt.scatter(x[y==1,3],x[y==1,4],c='orange', marker='o',label='clu2')\n",
    "# plt.scatter(x[y==2,2],x[y==2,4],c='lightblue', marker='v',label='clu3')\n",
    "# plt.scatter(x[y==3,2],x[y==3,4],c='b', marker='^',label='clu4')\n",
    "\n",
    "# cluster.center\n",
    "plt.scatter(Kmeans.cluster_centers_[:,3],Kmeans.cluster_centers_[:,4],c='red', marker='*',label='center')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p['kmeansResult']=Kmeans.labels_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p['compare'] = np.where(df_p['Loss on Dispostion'] == df_p['kmeansResult'], '0', '1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p['compare'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4182/len(df_p['compare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(df_p['Loss on Dispostion'], df_p['kmeansResult'])\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(df_p['Loss on Dispostion'], df_p['kmeansResult'], target_names=['current', 'default']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "g = sns.clustermap(x,cmap=\"mako\", robust=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some setting for this notebook to actually show the graphs inline\n",
    "# you probably won't need this\n",
    "%matplotlib inline\n",
    "np.set_printoptions(precision=5, suppress=True)  # suppress scientific float notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the linkage matrix\n",
    "# agglomerative hierarchical clustering (bottom up) - Ward Linkage Method\n",
    "\n",
    "Z = linkage(x, 'ward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import cophenet\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "c, coph_dists = cophenet(Z, pdist(x))\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate full dendrogram\n",
    "plt.figure(figsize=(25, 10))\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('customer index')\n",
    "plt.ylabel('distance')\n",
    "dendrogram(\n",
    "    Z,\n",
    "    leaf_rotation=90.,  # rotates the x axis labels\n",
    "    leaf_font_size=8.,  # font size for the x axis labels\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
